# ğŸ•‰ï¸ Divine Knowledge Portal  
### Bhagavad Gita Explorer + GitaGPT (Context-Aware AI Spiritual Assistant)

A full-stack AI-powered spiritual portal that combines structured scripture access with a context-aware conversational AI built using Retrieval-Augmented Generation (RAG).

---

# ğŸš€ Project Overview

The Divine Knowledge Portal is a hybrid AI system that integrates structured scripture exploration with retrieval-grounded conversational AI.

1. ğŸ“– Structured Bhagavad Gita exploration
2. ğŸ” Semantic verse search
3. ğŸ§  Context-aware AI dialogue (GitaGPT)
4. ğŸ’¾ Session-based memory
5. ğŸ¯ Retrieval-augmented response generation

It demonstrates retrieval-grounded conversational AI applied to a structured spiritual corpus.

## ğŸ–¼ï¸ GitaGPT Preview

![GitaGPT](assests/images/GitaGPT.png)

---

# âœ¨ Key Features

## 1ï¸âƒ£ Bhagavad Gita Explorer

- Structured verse browsing
- Shloka + English meaning display
- Word-wise meaning of all Sanskrit words
- Clean verse formatting
- Chapter-wise scripture access
- Lightweight and readable interface

---

## 2ï¸âƒ£ GitaGPT (AI Spiritual Guide)

- Semantic verse grounding
- Context-aware follow-up detection
- Persona-controlled concise responses

---

# ğŸ—ï¸ System Architecture

```
User Query
     â†“
Intent & Follow-up Detection
     â†“
Semantic Embedding (MiniLM)
     â†“
FAISS Vector Search
     â†“
Contextual Relevance Scoring
     â†“
Verse Selection
     â†“
TinyLlama Persona Generation
     â†“
Response + Session Memory Update
```

---

# ğŸ§© Retrieval Strategy

- Embedding dimension: 384
- Similarity metric: Cosine similarity
- Top-k retrieval: k=5
- Threshold gating to prevent weak matches

---

# ğŸ” How Retrieval Works

1. User query converted to embedding.
2. FAISS retrieves top-k similar verses.
3. Similarity threshold applied.
4. If score is strong â†’ verse is injected.
5. If weak â†’ direct AI wisdom.
6. LLM generates grounded response.

This prevents:
- Random verse injection
- Hallucinated references
- Topic misalignment

---

# ğŸ§  Core Technologies Used

| Component | Technology |
|------------|------------|
| Backend | Flask |
| Embeddings | SentenceTransformers (all-MiniLM-L6-v2, 384-dim, cosine similarity) |
| Vector Search | FAISS |
| LLM | TinyLlama 1.1B Chat |
| Session Memory | Flask session storage |
| Dataset | Structured Bhagavad Gita CSV |

---

# âš™ï¸ Design Considerations

âœ” Uses CPU-based inference for accessibility  
âœ” Limits conversation history for memory efficiency  
âœ” Applies similarity threshold to prevent weak retrieval  
âœ” Avoids hardcoded emotional keyword rules  
âœ” Separates retrieval and generation layers  

---

# ğŸ“Œ Architectural Decisions

âœ” Chose MiniLM for lightweight semantic embeddings  
âœ” Used FAISS for efficient in-memory vector similarity  
âœ” Implemented threshold-based gating to reduce irrelevant verse injection  
âœ” Separated retrieval and generation layers for modularity  
âœ” Designed session memory to balance context and efficiency  

---

# ğŸ“Š Project Highlights

This project demonstrates:

âœ” End-to-end AI system design  
âœ” Retrieval-Augmented Generation (RAG)  
âœ” Vector database integration (FAISS)  
âœ” Context tracking & conversational memory  
âœ” Persona conditioning  
âœ” Prompt engineering  
âœ” Lightweight LLM deployment on CPU  
âœ” Applied NLP system implementation  

---

# ğŸ›  Installation & Setup

## 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/PNSC21/divine-knowledge.git
cd divine-knowledge
```

## 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

## 3ï¸âƒ£ Run Application

```bash
python app.py
```

Visit:

```
http://127.0.0.1:5000
```

---

# ğŸ¯ Why This Project Stands Out

- Builds embeddings locally
- Uses vector similarity search
- Implements contextual gating
- Controls persona tone
- Maintains structured session memory

It reflects system-level thinking, not just API usage.

---

# ğŸ“ˆ Future Improvements

- Upgrade to larger LLM (e.g., Llama 3 / Mistral)
- Multi-verse contextual synthesis
- Cloud deployment (AWS / GCP)
- User-level conversation history persistence
- Chapter-wise semantic clustering 

---

# ğŸ§˜ Vision

To build structured, context-aware AI systems that responsibly integrate classical knowledge with modern NLP techniques -  while preserving contextual integrity and philosophical depth.

---

If you found this project interesting, feel free to connect or contribute.
